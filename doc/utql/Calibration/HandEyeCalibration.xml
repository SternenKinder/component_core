<?xml version="1.0" encoding="UTF-8"?>

<UTQLPatternTemplates xmlns='http://ar.in.tum.de/ubitrack/utql'
                      xmlns:xsi='http://www.w3.org/2001/XMLSchema-instance'
                      xmlns:xi='http://www.w3.org/2001/XInclude'
                      xmlns:h="http://www.w3.org/1999/xhtml"
                      xsi:schemaLocation='http://ar.in.tum.de/ubitrack/utql ../../schema/utql_templates.xsd'>
    
    <Pattern name="HECalibration" displayName="Hand-Eye Calibration (time-expansion)">
    	<Description><h:p>The classical application of Hand-eye calibration comes from the field of robotics.
    	A robot can, using internal sensors, determine the position of its hand, on which a camera (the eye)
    	is rigidly mounted. An object, which is not moving, is lying on the table in front of the robot and 
    	can be tracked by the camera. If the robot moves to three different positions, resulting in two 
    	independent motion-pairs, the hand-eye calibration can compute both the pose of the camera on the 
    	robot's hand and the pose of the object relative to the robot's base coordinate system.<h:br/>

		Besides its classical application in robotics, the hand-eye calibration is used for tracker alignment 
		when the systems are based on different technologies, so there is no single target that can be tracked 
		by both tracking systems. Instead, two rigidly connected targets are moved through the common tracking 
		area. From corresponding motion pairs, the hand-eye calibration algorithm can compute both the 
		transformations between the trackers and the two targets.</h:p></Description>
			    	
        <Input>
            <Node name="Robot" displayName="Robot"/>
            <Node name="Hand" displayName="Hand"/>
            <Node name="Eye" displayName="Eye"/>
            <Node name="Object" displayName="Calibration object"/>
            <Edge name="HandPose" displayName="Hand pose" source="Robot" destination="Hand">
                <Predicate>type=='6D'</Predicate>
            </Edge>
            <Edge name="ObjectPose" displayName="Calibration object pose" source="Eye" destination="Object">
                <Predicate>type=='6D'</Predicate>
            </Edge>
        </Input>
        
        <Output>
            <Edge name="Output" displayName="Hand-Eye" source="Hand" destination="Eye">
                <Attribute name="type" value="6D" xsi:type="EnumAttributeReferenceType"/>
            </Edge>
        </Output>
        
        <Constraints>
            <Correspondence name="pointCorrespondences" minMultiplicity="3">
                <Edge edge-ref="HandPose"/>
                <Edge edge-ref="ObjectPose"/>
            </Correspondence>

            <TriggerGroup>
                <Edge edge-ref="HandPose"/>
                <Edge edge-ref="ObjectPose"/>
                <Edge edge-ref="Output"/>
            </TriggerGroup>
        </Constraints>
        
        <DataflowConfiguration>
            <UbitrackLib class="HECalibration"/>
            
            <Attribute name="expansion" value="time" xsi:type="EnumAttributeReferenceType"/>
        </DataflowConfiguration>
    </Pattern>
    
    <Pattern name="HECalibrationSpace" displayName="Hand-Eye Calibration (space-expansion)">
    	<Description><h:p>The classical application of Hand-eye calibration comes from the field of robotics.
    	A robot can, using internal sensors, determine the position of its hand, on which a camera (the eye)
    	is rigidly mounted. An object, which is not moving, is lying on the table in front of the robot and 
    	can be tracked by the camera. If the robot moves to three different positions, resulting in two 
    	independent motion-pairs, the hand-eye calibration can compute both the pose of the camera on the 
    	robot's hand and the pose of the object relative to the robot's base coordinate system.<h:br/>

		Besides its classical application in robotics, the hand-eye calibration is used for tracker alignment 
		when the systems are based on different technologies, so there is no single target that can be tracked 
		by both tracking systems. Instead, two rigidly connected targets are moved through the common tracking 
		area. From corresponding motion pairs, the hand-eye calibration algorithm can compute both the 
		transformations between the trackers and the two targets.</h:p></Description>
			    	
        <Input>
            <Node name="Robot" displayName="Robot"/>
            <Node name="Hand" displayName="Hand"/>
            <Node name="Eye" displayName="Eye"/>
            <Node name="Object" displayName="Calibration object"/>
            <Edge name="HandPose" displayName="Hand pose" source="Robot" destination="Hand">
                <Predicate>type=='PoseList'</Predicate>
            </Edge>
            <Edge name="ObjectPose" displayName="Calibration object pose" source="Eye" destination="Object">
                <Predicate>type=='PoseList'</Predicate>
            </Edge>
        </Input>
        
        <Output>
            <Edge name="Output" displayName="Hand-Eye" source="Hand" destination="Eye">
                <Attribute name="type" value="6D" xsi:type="EnumAttributeReferenceType"/>
            </Edge>
        </Output>
        
        <Constraints>
            <Correspondence name="pointCorrespondences" minMultiplicity="3">
                <Edge edge-ref="HandPose"/>
                <Edge edge-ref="ObjectPose"/>
            </Correspondence>

            <TriggerGroup>
                <Edge edge-ref="HandPose"/>
                <Edge edge-ref="ObjectPose"/>
                <Edge edge-ref="Output"/>
            </TriggerGroup>
        </Constraints>
        
        <DataflowConfiguration>
            <UbitrackLib class="HECalibration"/>
            
            <Attribute name="expansion" value="space" xsi:type="EnumAttributeReferenceType"/>
        </DataflowConfiguration>
    </Pattern>

    
    <!-- Attribute declarations -->
    
    <GlobalNodeAttributeDeclarations>
        <xi:include href="file:GlobalAttrSpec.xml" xpointer="element(/1/1/1)"/>
    </GlobalNodeAttributeDeclarations>
    
    <GlobalEdgeAttributeDeclarations>
        <xi:include href="file:GlobalAttrSpec.xml" xpointer="element(/1/2/1)"/>
        <xi:include href="file:GlobalAttrSpec.xml" xpointer="element(/1/2/2)"/>
        <xi:include href="file:GlobalAttrSpec.xml" xpointer="element(/1/2/3)"/>
        <xi:include href="file:GlobalAttrSpec.xml" xpointer="element(/1/2/4)"/>
        <xi:include href="file:GlobalAttrSpec.xml" xpointer="element(/1/2/5)"/>
        <xi:include href="file:GlobalAttrSpec.xml" xpointer="element(/1/2/6)"/>
        <xi:include href="file:GlobalAttrSpec.xml" xpointer="element(/1/2/7)"/>
        <xi:include href="file:GlobalAttrSpec.xml" xpointer="element(/1/2/8)"/>
    </GlobalEdgeAttributeDeclarations> 

    <GlobalDataflowAttributeDeclarations>
        <!-- Unfortunately, the xpointer used in Xinclude is currently restricted to the element scheme and absolute element indices in Xerces (and thus XMLBeans) -->
        <xi:include href="file:GlobalAttrSpec.xml" xpointer="element(/1/3/1)"/>
        <xi:include href="file:GlobalAttrSpec.xml" xpointer="element(/1/3/2)"/>
    </GlobalDataflowAttributeDeclarations>
    
</UTQLPatternTemplates>
